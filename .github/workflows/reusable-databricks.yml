name: reusable-databricks

on:
  workflow_call:
    inputs:
      mode:
        description: "Which lifecycle to run: ci-dev | ci-test | cd-prod"
        required: true
        type: string
      bundle_path:
        description: "Path to the Databricks Asset Bundle (contains databricks.yml)"
        required: true
        type: string
      target:
        description: "Databricks bundle target name (e.g., dev, test, prod)"
        required: true
        type: string
      environment_name:
        description: "GitHub Environment name to apply for secrets/approvals (e.g., DataBricks-Test)"
        required: true
        type: string
      artifact_name:
        description: "Artifact name for build outputs (if applicable)"
        required: false
        default: "dw_bundle_artifact"
        type: string

      run_asset_validation:
        description: "Run metadata-driven asset validation job after deploy (ci-test recommended)"
        required: false
        default: true
        type: boolean
      asset_validation_notebook_path:
        description: "Databricks notebook path for asset validation driver"
        required: false
        default: "/Repos/ci/asset_validation_driver"
        type: string
      asset_validation_cluster_id_secret:
        description: "Name of the GitHub secret containing the cluster id used for validations"
        required: false
        default: "DATABRICKS_VALIDATION_CLUSTER_ID"
        type: string

      promote_artifact_only:
        description: "If true, skip build and only deploy a previously-built artifact (cd-prod use-case)"
        required: false
        default: false
        type: boolean

      run_post_deployment_tests:
        description: "Run post-deploy tests (summary + optional smoke)."
        required: false
        default: false
        type: boolean
      post_deploy_summary_output:
        description: "Output format for databricks bundle summary: text | json | both"
        required: false
        default: "text"
        type: string

      # Job/Notebook smoke (compute plane)
      run_post_deploy_smoke:
        description: "If true, run a job/notebook smoke test after deploy (compute plane)."
        required: false
        default: false
        type: boolean
      smoke_mode:
        description: "How to run job/notebook smoke tests: notebook | bundle-run"
        required: false
        default: "notebook"
        type: string
      smoke_notebook_path:
        description: "Notebook path used for smoke (when smoke_mode=notebook)"
        required: false
        default: ""
        type: string
      smoke_job_key:
        description: "Job key to run via databricks bundle run (when smoke_mode=bundle-run)"
        required: false
        default: ""
        type: string

      # SQL Warehouse smoke (serving plane)
      run_sql_smoke:
        description: "If true, run SQL smoke tests against a Databricks SQL Warehouse after deploy."
        required: false
        default: false
        type: boolean
      sql_warehouse_id_secret:
        description: "Name of the GitHub secret containing the SQL Warehouse ID."
        required: false
        default: "DATABRICKS_SQL_WAREHOUSE_ID"
        type: string
      sql_smoke_queries:
        description: |
          "One SQL statement per line to execute as post-deploy smoke (examples: SELECT 1; SHOW SCHEMAS; SELECT count(*) FROM ...)."
        required: false
        default: |
          SELECT 1
        type: string

      # Governance maturity (telemetry first, enforcement later)
      run_maturity_collect:
        description: "If true, run maturity metric collection after deploy (safe; never fails)."
        required: false
        default: false
        type: boolean
      run_maturity_ci_check:
        description: "If true, run maturity CI gate check after deploy (may fail depending on enforcement_mode / override)."
        required: false
        default: false
        type: boolean
      maturity_enforcement_mode:
        description: "Override enforcement mode for this run: off|warn|block. Empty means use config table."
        required: false
        default: ""
        type: string
      maturity_override:
        description: "Override behavior for this run: none|warn_only|skip"
        required: false
        default: "none"
        type: string
      bundle_name:
        description: "Bundle name for deployment tracking (governance_maturity.bundle_deployments)"
        required: false
        default: ""
        type: string

    secrets:
      DATABRICKS_HOST:
        required: true
      DATABRICKS_TOKEN:
        required: true
      DATABRICKS_VALIDATION_CLUSTER_ID:
        required: true
      DATABRICKS_SQL_WAREHOUSE_ID:
        required: true

jobs:
  databricks:
    name: ${{ inputs.mode }}
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment_name }}
    permissions:
      contents: read
    env:
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
      DATABRICKS_VALIDATION_CLUSTER_ID: ${{ secrets.DATABRICKS_VALIDATION_CLUSTER_ID }}
      BUNDLE_PATH: ${{ inputs.bundle_path }}
      TARGET: ${{ inputs.target }}
      ARTIFACT_NAME: ${{ inputs.artifact_name }}
      MODE: ${{ inputs.mode }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install tooling
        run: |
          python -m pip install --upgrade pip
          # Do NOT install legacy databricks-cli (it overrides the `databricks` command)
          pip install databricks-sdk
          sudo apt-get update
          sudo apt-get install -y jq zip
          curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh
          databricks version
          databricks bundle -h

      - name: Validate inputs
        run: |
          case "$MODE" in
            ci-dev|ci-test|cd-prod) ;;
            *) echo "Invalid mode: $MODE (expected ci-dev|ci-test|cd-prod)"; exit 2;;
          esac

          if [ ! -f "$BUNDLE_PATH/databricks.yml" ] && [ ! -f "$BUNDLE_PATH/databricks.yaml" ]; then
            echo "Could not find databricks.yml under bundle_path: $BUNDLE_PATH"
            exit 2
          fi

          case "${{ inputs.post_deploy_summary_output }}" in
            text|json|both) ;;
            *) echo "Invalid post_deploy_summary_output: ${{ inputs.post_deploy_summary_output }} (expected text|json|both)"; exit 2;;
          esac

          case "${{ inputs.smoke_mode }}" in
            notebook|bundle-run) ;;
            *) echo "Invalid smoke_mode: ${{ inputs.smoke_mode }} (expected notebook|bundle-run)"; exit 2;;
          esac

          case "${{ inputs.maturity_override }}" in
            none|warn_only|skip) ;;
            *) echo "Invalid maturity_override: ${{ inputs.maturity_override }} (expected none|warn_only|skip)"; exit 2;;
          esac

          if [ -n "${{ inputs.maturity_enforcement_mode }}" ]; then
            case "${{ inputs.maturity_enforcement_mode }}" in
              off|warn|block) ;;
              *) echo "Invalid maturity_enforcement_mode: ${{ inputs.maturity_enforcement_mode }} (expected off|warn|block)"; exit 2;;
            esac
          fi

      - name: Bundle validate
        run: |
          cd "$BUNDLE_PATH"
          databricks bundle validate --target "$TARGET" --var="validation_cluster_id=$DATABRICKS_VALIDATION_CLUSTER_ID"

      - name: Package bundle content (artifact)
        if: ${{ inputs.promote_artifact_only == false }}
        run: |
          mkdir -p dist
          zip -r "dist/${ARTIFACT_NAME}.zip" "$BUNDLE_PATH" -x "*.git*"

      - name: Upload artifact
        if: ${{ inputs.promote_artifact_only == false }}
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.artifact_name }}
          path: dist/${{ inputs.artifact_name }}.zip
          if-no-files-found: error
          retention-days: 14

      - name: Bundle deploy
        run: |
          cd "$BUNDLE_PATH"
          databricks bundle deploy --target "$TARGET" --auto-approve --var="validation_cluster_id=$DATABRICKS_VALIDATION_CLUSTER_ID"

      - name: Maturity metrics collection (bundle run)
        if: ${{ inputs.run_maturity_collect }}
        run: |
          cd "$BUNDLE_PATH"
          databricks bundle run maturity_collect             --target "$TARGET"             --var="validation_cluster_id=$DATABRICKS_VALIDATION_CLUSTER_ID"             --params env="$TARGET"             --params run_id="${GITHUB_RUN_ID}"             --params commit_sha="${GITHUB_SHA}"             --params repo="${GITHUB_REPOSITORY}"             --params git_ref="${GITHUB_REF}"             --params workflow_run_id="${GITHUB_RUN_ID}"             --params bundle_name="${{ inputs.bundle_name }}"

      - name: Maturity CI gate check (bundle run)
        if: ${{ inputs.run_maturity_ci_check }}
        run: |
          cd "$BUNDLE_PATH"
          databricks bundle run maturity_ci_check             --target "$TARGET"             --var="validation_cluster_id=$DATABRICKS_VALIDATION_CLUSTER_ID"             --params env="$TARGET"             --params enforcement_mode="${{ inputs.maturity_enforcement_mode }}"             --params maturity_override="${{ inputs.maturity_override }}"
